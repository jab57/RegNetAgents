# RegNetAgents - Environment Configuration
# Copy this file to .env and customize for your environment

# ============================================================
# Ollama LLM Configuration (for domain agents)
# ============================================================

# Ollama server host (default: localhost)
OLLAMA_HOST=http://localhost:11434

# Ollama model to use for domain analysis
# Options: llama3.1:8b (recommended), mistral:7b, phi3:mini
OLLAMA_MODEL=llama3.1:8b

# Enable/disable LLM-powered agents (true/false)
# Set to 'false' to use rule-based fallback only
USE_LLM_AGENTS=true

# ============================================================
# Performance Tuning
# ============================================================

# Timeout for LLM calls (seconds)
OLLAMA_TIMEOUT=30

# Temperature for LLM inference (0.0-1.0)
# Lower = more deterministic, higher = more creative
# Recommended: 0.3 for scientific analysis
OLLAMA_TEMPERATURE=0.3

# Maximum tokens for LLM response
OLLAMA_MAX_TOKENS=1500

# ============================================================
# Notes
# ============================================================
#
# Before using LLM agents:
# 1. Install Ollama: https://ollama.com/download
# 2. Pull model: ollama pull llama3.1:8b
# 3. Verify: ollama run llama3.1:8b "Hello"
#
# Ollama runs as background service (no manual start needed after install)
